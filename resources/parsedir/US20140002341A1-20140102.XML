<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v43-2012-12-04.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.3 2012-12-04" file="US20140002341A1-20140102.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20131218" date-publ="20140102"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20140002341</doc-number><kind>A1</kind><date>20140102</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>13536778</doc-number><date>20120628</date></document-id></application-reference><us-application-series-code>13</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>09</class><subclass>G</subclass><main-group>5</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20140102</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classification-national><country>US</country><main-classification>345156</main-classification></classification-national><invention-title id="d0e43">EYE-TYPING TERM RECOGNITION</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only"><addressbook><last-name>Nister</last-name><first-name>David</first-name><address><city>Bellevue</city><state>WA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant><us-applicant sequence="01" app-type="applicant" designation="us-only"><addressbook><last-name>Thukral</last-name><first-name>Vaibhav</first-name><address><city>Kirkland</city><state>WA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant><us-applicant sequence="02" app-type="applicant" designation="us-only"><addressbook><last-name>Nijemcevic</last-name><first-name>Djordje</first-name><address><city>Kragujevac</city><country>RS</country></address></addressbook><residence><country>RS</country></residence></us-applicant><us-applicant sequence="03" app-type="applicant" designation="us-only"><addressbook><last-name>Bhargava</last-name><first-name>Ruchi</first-name><address><city>Redmond</city><state>WA</state><country>US</country></address></addressbook><residence><country>US</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Nister</last-name><first-name>David</first-name><address><city>Bellevue</city><state>WA</state><country>US</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Thukral</last-name><first-name>Vaibhav</first-name><address><city>Kirkland</city><state>WA</state><country>US</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>Nijemcevic</last-name><first-name>Djordje</first-name><address><city>Kragujevac</city><country>RS</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>Bhargava</last-name><first-name>Ruchi</first-name><address><city>Redmond</city><state>WA</state><country>US</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Various embodiments related to entering text into a computing device via eye-typing are disclosed. For example, one embodiment provides a method that includes receiving a data set including a plurality of gaze samples, each gaze sample including a gaze location and a corresponding point in time. The method further comprises processing the plurality of gaze samples to determine one or more likely terms represented by the data set.</p></abstract></us-patent-application>