<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v43-2012-12-04.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.3 2012-12-04" file="US20140003726A1-20140102.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20131218" date-publ="20140102"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20140003726</doc-number><kind>A1</kind><date>20140102</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>14018005</doc-number><date>20130904</date></document-id></application-reference><us-application-series-code>14</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>KR</country><doc-number>10-2008-0058069</doc-number><date>20080619</date></priority-claim><priority-claim sequence="02" kind="national"><country>KR</country><doc-number>10-2008-0122637</doc-number><date>20081204</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>K</subclass><main-group>9</main-group><subgroup>78</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20140102</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>K</subclass><main-group>9</main-group><subgroup>78</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20140102</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc></classifications-cpc><classification-national><country>US</country><main-classification>382209</main-classification></classification-national><invention-title id="d0e79">METHOD AND APPARATUS FOR RECOGNIZING CHARACTERS</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>13658319</doc-number><date>20121023</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>8553987</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>14018005</doc-number></document-id></child-doc></relation></continuation><continuation><relation><parent-doc><document-id><country>US</country><doc-number>12487378</doc-number><date>20090618</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>8320681</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>13658319</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Samsung Electronics Co., Ltd.</orgname><address><city>Gyeonggi-do</city><country>KR</country></address></addressbook><residence><country>KR</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>KIM</last-name><first-name>Hyun-Soo</first-name><address><city>Gyeonggi-do</city><country>KR</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>HWANG</last-name><first-name>Seong-Taek</first-name><address><city>Gyeonggi-do</city><country>KR</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>OH</last-name><first-name>Sang-Wook</first-name><address><city>Gyeonggi-do</city><country>KR</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>KIM</last-name><first-name>Sang-Ho</first-name><address><city>Gyeonggi-do</city><country>KR</country></address></addressbook></inventor><inventor sequence="04" designation="us-only"><addressbook><last-name>OH</last-name><first-name>Yun-Je</first-name><address><city>Gyeonggi-do</city><country>KR</country></address></addressbook></inventor><inventor sequence="05" designation="us-only"><addressbook><last-name>JUNG</last-name><first-name>Hee-Won</first-name><address><city>Gyeonggi-do</city><country>KR</country></address></addressbook></inventor><inventor sequence="06" designation="us-only"><addressbook><last-name>KIM</last-name><first-name>Sung-Cheol</first-name><address><city>Gyeonggi-do</city><country>KR</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>Samsung Electronics Co., Ltd.</orgname><role>03</role><address><city>Gyeonggi-do</city><country>KR</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A method and an apparatus for recognizing characters using an image are provided. A camera is activated according to a character recognition request and a preview mode is set for displaying an image photographed through the camera in real time. An auto focus of the camera is controlled and an image having a predetermined level of clarity is obtained for character recognition from the images obtained in the preview mode. The image for character recognition is character-recognition-processed so as to extract recognition result data. A final recognition character row is drawn that excludes non-character data from the recognition result data. A first word is combined including at least one character of the final recognition character row and a predetermined maximum number of characters. A dictionary database that stores dictionary information on various languages using the first word is searched, so as to provide the user with the corresponding word.</p></abstract></us-patent-application>