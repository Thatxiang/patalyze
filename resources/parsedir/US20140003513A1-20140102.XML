<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v43-2012-12-04.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.3 2012-12-04" file="US20140003513A1-20140102.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20131218" date-publ="20140102"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20140003513</doc-number><kind>A1</kind><date>20140102</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>14015476</doc-number><date>20130830</date></document-id></application-reference><us-application-series-code>14</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>KR</country><doc-number>10-2009-0075335</doc-number><date>20090814</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>7</main-group><subgroup>32</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20140102</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>19</main-group><subgroup>00569</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20140102</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc></classifications-cpc><classification-national><country>US</country><main-classification>37524012</main-classification></classification-national><invention-title id="d0e61">METHOD AND APPARATUS FOR ENCODING VIDEO, AND METHOD AND APPARATUS FOR DECODING VIDEO</invention-title><us-related-documents><continuation><relation><parent-doc><document-id><country>US</country><doc-number>13764414</doc-number><date>20130211</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>8526497</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>14015476</doc-number></document-id></child-doc></relation></continuation><continuation><relation><parent-doc><document-id><country>US</country><doc-number>12856078</doc-number><date>20100813</date></document-id><parent-grant-document><document-id><country>US</country><doc-number>8374241</doc-number></document-id></parent-grant-document></parent-doc><child-doc><document-id><country>US</country><doc-number>13764414</doc-number></document-id></child-doc></relation></continuation></us-related-documents><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>SAMSUNG ELECTRONICS CO., LTD.</orgname><address><city>Suwon-si</city><country>KR</country></address></addressbook><residence><country>KR</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>CHEN</last-name><first-name>Jianle</first-name><address><city>Suwon-si</city><country>KR</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>CHEON</last-name><first-name>Min-su</first-name><address><city>Suwon-si</city><country>KR</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>LEE</last-name><first-name>Jae-chool</first-name><address><city>Suwon-si</city><country>KR</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>MIN</last-name><first-name>Jung-hye</first-name><address><city>Suwon-si</city><country>KR</country></address></addressbook></inventor><inventor sequence="04" designation="us-only"><addressbook><last-name>JUNG</last-name><first-name>Hae-kyung</first-name><address><city>Seoul</city><country>KR</country></address></addressbook></inventor><inventor sequence="05" designation="us-only"><addressbook><last-name>KIM</last-name><first-name>Il-koo</first-name><address><city>Osan-si</city><country>KR</country></address></addressbook></inventor><inventor sequence="06" designation="us-only"><addressbook><last-name>LEE</last-name><first-name>Sang-rae</first-name><address><city>Suwon-si</city><country>KR</country></address></addressbook></inventor><inventor sequence="07" designation="us-only"><addressbook><last-name>LEE</last-name><first-name>Kyo-hyuk</first-name><address><city>Yongin-si</city><country>KR</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>SAMSUNG ELECTRONICS CO., LTD.</orgname><role>03</role><address><city>Suwon-si</city><country>KR</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Disclosed is a method of encoding a video, the method including: splitting a current picture into at least one maximum coding unit; determining a coded depth to output a final encoding result according to at least one split region obtained by splitting a region of the maximum coding unit according to depths, by encoding the at least one split region, based on a depth that deepens in proportion to the number of times the region of the maximum coding unit is split; and outputting image data constituting the final encoding result according to the at least one split region, and encoding information about the coded depth and a prediction mode, according to the at least one maximum coding unit.</p></abstract></us-patent-application>