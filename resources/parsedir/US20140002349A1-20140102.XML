<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v43-2012-12-04.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.3 2012-12-04" file="US20140002349A1-20140102.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20131218" date-publ="20140102"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20140002349</doc-number><kind>A1</kind><date>20140102</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>13882476</doc-number><date>20101029</date></document-id></application-reference><us-application-series-code>13</us-application-series-code><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>01</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20140102</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>013</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20140102</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc></classifications-cpc><classification-national><country>US</country><main-classification>345156</main-classification></classification-national><invention-title id="d0e43">Method of Determining Reflections of Light</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only"><addressbook><last-name>Hansen</last-name><first-name>Dan Witzner</first-name><address><city>Olstykke</city><country>DK</country></address></addressbook><residence><country>DK</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Hansen</last-name><first-name>Dan Witzner</first-name><address><city>Olstykke</city><country>DK</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>IT-UNIVERSITETET I K&#xd8;BENHAVN</orgname><role>03</role><address><city>Copenhangen S</city><country>DK</country></address></addressbook></assignee></assignees><pct-or-regional-filing-data><document-id><country>WO</country><doc-number>PCT/EP2010/066495</doc-number><kind>00</kind><date>20101029</date></document-id><us-371c124-date><date>20130916</date></us-371c124-date></pct-or-regional-filing-data></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A method of filtering glints by processing an image of a user's cornea to obtain coordinates of desired glints from a configuration of light sources, comprising processing an image, in a first image space, of a user's cornea to determine coordinates of respective multiple positions of glints; and iteratively: selecting from the coordinates a first and a second set of coordinates; computing from the first set of coordinates a transformation that transforms the first set of coordinates into first coordinates of a predetermined spatial configuration; and testing whether the transformation transforms also the second set into positions that match second positions of the predetermined configuration. The coordinates of the desired glints are selected as those first and second sets which are transformed into coordinates that match the first and second coordinates of the predetermined configuration. The method is based on a geometrical homography and is expedient for robust gaze estimation in connection with e.g. eye tracking.</p></abstract></us-patent-application>