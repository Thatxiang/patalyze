<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v43-2012-12-04.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.3 2012-12-04" file="US20140002350A1-20140102.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20131218" date-publ="20140102"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20140002350</doc-number><kind>A1</kind><date>20140102</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>13923066</doc-number><date>20130620</date></document-id></application-reference><us-application-series-code>13</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>CN</country><doc-number>201210226823.7</doc-number><date>20120629</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>01</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20140102</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>F</subclass><main-group>3</main-group><subgroup>01</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20140102</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc></classifications-cpc><classification-national><country>US</country><main-classification>345156</main-classification></classification-national><invention-title id="d0e61">ELECTRONIC DEVICE AND METHOD FOR PROCESSING AN OBJECT</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>LENOVO (BEIJING) LIMITED</orgname><address><city>Beijing</city><country>CN</country></address></addressbook><residence><country>CN</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Zhou</last-name><first-name>Zhiqiang</first-name><address><city>Beijing</city><country>CN</country></address></addressbook></inventor></inventors></us-parties><assignees><assignee><addressbook><orgname>LENOVO (BEIJING) LIMITED</orgname><role>03</role><address><city>Beijing</city><country>CN</country></address></addressbook></assignee></assignees></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Electronic devices and methods for processing an object in an electronic device are provided. The method includes: when a sensor unit detects that an operator is holding the electronic device, obtaining a first holding position parameter of the operator relative to an input unit; determining a correspondence between the object and the input unit based on the first holding position parameter; and outputting the object by a display unit based on the correspondence. The electronic device includes a processing unit configured to, when a sensor unit detects that an operator is holding the electronic device, obtaining a first holding position parameter of the operator relative to an input unit, determine a correspondence between the object and the input unit based on the first holding position parameter, and output the object via a display unit based on the correspondence.</p></abstract></us-patent-application>