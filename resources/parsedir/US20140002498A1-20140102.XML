<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v43-2012-12-04.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.3 2012-12-04" file="US20140002498A1-20140102.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20131218" date-publ="20140102"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20140002498</doc-number><kind>A1</kind><date>20140102</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>13925735</doc-number><date>20130624</date></document-id></application-reference><us-application-series-code>13</us-application-series-code><priority-claims><priority-claim sequence="01" kind="national"><country>KR</country><doc-number>10-2012-0069363</doc-number><date>20120627</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>G</section><class>06</class><subclass>T</subclass><main-group>19</main-group><subgroup>00</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20140102</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>G</section><class>06</class><subclass>T</subclass><main-group>19</main-group><subgroup>006</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20140102</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc></classifications-cpc><classification-national><country>US</country><main-classification>345633</main-classification></classification-national><invention-title id="d0e61">APPARATUS AND METHOD FOR CREATING SPATIAL AUGMENTED REALITY CONTENT</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>Electronics and Telecommunications Research Institute</orgname><address><city>Daejeon</city><country>KR</country></address></addressbook><residence><country>KR</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>LEE</last-name><first-name>Jun-Sup</first-name><address><city>Daejeon</city><country>KR</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>LEE</last-name><first-name>Su-Woong</first-name><address><city>Daejeon</city><country>KR</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>YOUN</last-name><first-name>Jin-Young</first-name><address><city>Seoul</city><country>KR</country></address></addressbook></inventor><inventor sequence="03" designation="us-only"><addressbook><last-name>LIM</last-name><first-name>Suk-Hyun</first-name><address><city>Seoul</city><country>KR</country></address></addressbook></inventor><inventor sequence="04" designation="us-only"><addressbook><last-name>LEE</last-name><first-name>Gil-Haeng</first-name><address><city>Seoul</city><country>KR</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">Disclosed herein is an apparatus and method for creating spatial augmented reality content, which enable interaction with a user. In the method, a stationary object in a real space in which a user is located is defined, and then a virtual space is generated. A dynamic object in the real space is defined, and the dynamic object is converted into a primitive object. The primitive object is arranged in the virtual space and then spatial augmented content is created. A multimedia object is paired with the primitive object, and then a virtual space object is generated. Interaction between the virtual space object and a gesture of the user is defined in a format of event script. The virtual space object and the interaction are packaged in the spatial augmented content and packaged results are provided to the user.</p></abstract></us-patent-application>