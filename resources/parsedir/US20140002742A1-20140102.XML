<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE us-patent-application SYSTEM "us-patent-application-v43-2012-12-04.dtd" [ ]><us-patent-application lang="EN" dtd-version="v4.3 2012-12-04" file="US20140002742A1-20140102.XML" status="PRODUCTION" id="us-patent-application" country="US" date-produced="20131218" date-publ="20140102"><us-bibliographic-data-application lang="EN" country="US"><publication-reference><document-id><country>US</country><doc-number>20140002742</doc-number><kind>A1</kind><date>20140102</date></document-id></publication-reference><application-reference appl-type="utility"><document-id><country>US</country><doc-number>13928146</doc-number><date>20130626</date></document-id></application-reference><us-application-series-code>13</us-application-series-code><priority-claims><priority-claim sequence="01" kind="regional"><country>EP</country><doc-number>12305779.6</doc-number><date>20120629</date></priority-claim></priority-claims><classifications-ipcr><classification-ipcr><ipc-version-indicator><date>20060101</date></ipc-version-indicator><classification-level>A</classification-level><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>14</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20140102</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source></classification-ipcr></classifications-ipcr><classifications-cpc><main-cpc><classification-cpc><cpc-version-indicator><date>20130101</date></cpc-version-indicator><section>H</section><class>04</class><subclass>N</subclass><main-group>5</main-group><subgroup>14</subgroup><symbol-position>F</symbol-position><classification-value>I</classification-value><action-date><date>20140102</date></action-date><generating-office><country>US</country></generating-office><classification-status>B</classification-status><classification-data-source>H</classification-data-source><scheme-origination-code>C</scheme-origination-code></classification-cpc></main-cpc></classifications-cpc><classification-national><country>US</country><main-classification>348571</main-classification></classification-national><invention-title id="d0e61">METHOD FOR REFRAMING IMAGES OF A VIDEO SEQUENCE, AND APPARATUS FOR REFRAMING IMAGES OF A VIDEO SEQUENCE</invention-title><us-parties><us-applicants><us-applicant sequence="00" app-type="applicant" designation="us-only" applicant-authority-category="assignee"><addressbook><orgname>THOMSON LICENSING</orgname><address><city>Issy de Moulineaux</city><country>FR</country></address></addressbook><residence><country>FR</country></residence></us-applicant></us-applicants><inventors><inventor sequence="00" designation="us-only"><addressbook><last-name>Chamaret</last-name><first-name>Christel</first-name><address><city>Chantepie</city><country>FR</country></address></addressbook></inventor><inventor sequence="01" designation="us-only"><addressbook><last-name>Urban</last-name><first-name>Fabrice</first-name><address><city>Thorigne Fouillard</city><country>FR</country></address></addressbook></inventor><inventor sequence="02" designation="us-only"><addressbook><last-name>Chevance</last-name><first-name>Christophe</first-name><address><city>Brece</city><country>FR</country></address></addressbook></inventor></inventors></us-parties></us-bibliographic-data-application><abstract id="abstract"><p id="p-0001" num="0000">A reframing application crops a sub-part of a video source, based on its content. The reframing application involves a visual attention model that produces a saliency map, and a dedicated reframing algorithm that extrapolates a cropping window based on that saliency map. After cropping, only the reframed portion of each video image remains visible. A method for processing images of a video sequence comprises steps of determining parameters of the video sequence, parameters of a previously decoded subsequence of the video sequence and user settings, determining a portion to be cropped according to the determined parameters, and cropping in a reframing step the determined portion for being displayed. An advantage of the invention is that an advanced automatic solution is provided for tuning automatically the reframing parameters, based on the content of a video.</p></abstract></us-patent-application>